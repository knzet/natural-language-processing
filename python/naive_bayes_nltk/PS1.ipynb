{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51555464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def trainNaiveBayes(D, C):\n",
    "    #returns log P(x) and log P(w|c)\n",
    "    nDoc = len(D)  #NDoc=number of documents in D\n",
    "\n",
    "    logprior = {}\n",
    "    loglikelihood = {}\n",
    "    bigdoc = {\"POSITIVE\": \"\", \"NEGATIVE\": \"\"}\n",
    "    for c in C:  # C=[\"POSITIVE\",\"NEGATIVE\"]\n",
    "        #Nc = number of documents from D in class c\n",
    "        nc = 0\n",
    "        for d in D:\n",
    "            if (d.c == c):\n",
    "                nc += 1\n",
    "                bigdoc[c] += d.text  #bigdoc={'+':[\"123','1234'].'-'}\n",
    "        logprior[c] = math.log10(nc / nDoc)\n",
    "\n",
    "        sumWiC = 0  # going to be denominator of loglikelihood\n",
    "\n",
    "        # bigdoc[c] is a string with all documents in class concatenated, then we split and generate unigrams -> V\n",
    "        #V = list(ngrams(bigdoc[c].split(), 1))\n",
    "\n",
    "        # remove stopwords\n",
    "        stopWords = stopwords.words('english')\n",
    "        words = nltk.tokenize.word_tokenize(bigdoc[c])\n",
    "        nonStopWords = list(filter(lambda w: w not in stopWords, words))\n",
    "        # print(words[:10])\n",
    "        # print(nonStopWords[:10])\n",
    "        #V=vocabulary of D (unique unigram frequency list)\n",
    "        V = dict(nltk.FreqDist(nonStopWords).items()\n",
    "                 )  # this returns {'word1': 1, 'word2': 1, ...}\n",
    "        sumWiC = 0\n",
    "        print(len(nonStopWords))\n",
    "        for w in nonStopWords:  # TODO: maybe use an nltk builtin for this sum\n",
    "            # calculate sum over all w(i) in V, for denominator of loglikelihood\n",
    "            #sumWiC+=bigdoc[c].count(w)+1 # count occurrences of substring\n",
    "            sumWiC += V[w] + 1  # todo: replace with a reduce\n",
    "        # print(V[\"the\"])\n",
    "        print(sumWiC)\n",
    "        for w, countWC in V.items():  # calculate P(w|c) terms\n",
    "            #countWC=V[w]\n",
    "            #countWC=bigdoc[c].count(w) #number of occurrences of w in bigdoc[c]\n",
    "            loglikelihood[w, c] = math.log10(\n",
    "                (countWC + 1) / (sumWiC))  # laplace add-one smoothing\n",
    "    # print(logprior)\n",
    "    print('P(hebrew|pos): ', loglikelihood[('hebrew', 'POSITIVE')])\n",
    "    print('P(wish|neg): ', loglikelihood[('wish', 'NEGATIVE')])\n",
    "    # print(V)\n",
    "    return logprior, loglikelihood, V\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba954aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12060\n",
      "1186966\n",
      "11043\n",
      "1028000\n",
      "P(hebrew|pos):  -5.710963118995275\n",
      "P(wish|neg):  -5.47237828767392\n"
     ]
    }
   ],
   "source": [
    "class Document:\n",
    "    def __init__(self, text, c):\n",
    "        self.text = text\n",
    "        self.c = c\n",
    "\n",
    "\n",
    "docs = []\n",
    "docs.append(Document(\"test of of of of of document \", \"POSITIVE\"))\n",
    "docs.append(Document(\"test document test of the test document \", \"POSITIVE\"))\n",
    "docs.append(Document(\"bad bad sentence the \", \"NEGATIVE\"))\n",
    "docs.append(Document(\"strangely bad words in order \", \"NEGATIVE\"))\n",
    "\n",
    "C = {\"POSITIVE\", \"NEGATIVE\"}\n",
    "\n",
    "\n",
    "def parseTrainingData(fname):\n",
    "    with open(fname) as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    sents = list(map(lambda line: line.split('\\t'), lines))\n",
    "    sents = sents[0:-1]  # trailing newline\n",
    "    docs = list(map(lambda sent: Document(sent[1].lower(), sent[2]), sents))\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "docs = parseTrainingData('training.txt')\n",
    "# print(docs)\n",
    "logprior, loglikelihood, V = trainNaiveBayes(docs, C)\n",
    "# trainNaiveBayes({d1, d2}, {\"POSITIVE\"})\n",
    "\n",
    "\n",
    "def testNaiveBayes(testdoc, logprior, loglikelihood, C, V):  #returns best c\n",
    "    sum = {\"POSITIVE\": 0, \"NEGATIVE\": 0}\n",
    "    for c in C:\n",
    "        sum[c] = logprior[c]\n",
    "        for word in testdoc.text.split():\n",
    "            for vWord in V:\n",
    "                if (word == vWord):\n",
    "                    #this bit isnt working, so all the weights are coming out too big (negative)\n",
    "                    if (word, c) in loglikelihood:\n",
    "                        sum[c] += loglikelihood[word, c]\n",
    "    # print(testdoc.text + \" \" + str(max(sum.items(), key=lambda k: k[1])[0]))\n",
    "    # print(sum)  # for some reason the loglikelihood is coming out the same\n",
    "    return testdoc.c, max(sum.items(),\n",
    "                          key=lambda k: k[1])  # return max, comparing value\n",
    "\n",
    "\n",
    "####################################### test\n",
    "alltestdata = parseTrainingData('test.txt')\n",
    "\n",
    "\n",
    "# print(loglikelihood)\n",
    "def testFullData(alltestdata):\n",
    "    return list(\n",
    "        map(lambda doc: testNaiveBayes(doc, logprior, loglikelihood, C, V),\n",
    "            alltestdata))\n",
    "\n",
    "\n",
    "# print(testFullData(alltestdata))\n",
    "doc = testFullData(alltestdata)\n",
    "# count the number of docs we predicted correctly\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "# print(filter(lambda d: d[0] == d[1][0], doc))\n",
    "pcount = 0\n",
    "ncount = 0\n",
    "for d in doc:\n",
    "    #does the test doc class match the predicted class?\n",
    "    # if d[0] == d[1][0]:\n",
    "    #     tp += 1\n",
    "\n",
    "    if d[0] == \"POSITIVE\":\n",
    "        # pcount += 1\n",
    "        if d[1][0] == \"NEGATIVE\":\n",
    "            fp += 1\n",
    "        if d[1][0] == \"POSITIVE\":\n",
    "            tp += 1\n",
    "    if d[0] == \"NEGATIVE\":\n",
    "        # ncount += 1\n",
    "        if d[1][0] == \"POSITIVE\":\n",
    "            fn += 1\n",
    "        if d[1][0] == \"NEGATIVE\":\n",
    "            tn += 1\n",
    "\n",
    "# print('tp: ', tp)\n",
    "# print('fp: ', fp)\n",
    "# print('tn: ', tn)\n",
    "# print('fn: ', fn)\n",
    "# print('recall: ', tp / (tp + fn))\n",
    "# print('precision: ', tp / (tp + fp))\n",
    "# print('specificity: ', tn / (tn + fp))\n",
    "# print('false positive: ', fp / (tn + fp))\n",
    "# print(\"tp/all\" :str(tp / len(doc))) # accuracy=number correct pos+neg predictions/total predictions\n",
    "# map(lambda x: x, fulldata)\n",
    "\n",
    "# print(V['singapore-based'])\n",
    "# testdoc = Document(\"test of bad bad bad bad bad sentence bad\", \"NEGATIVE\")\n",
    "# print(doc[4].text)\n",
    "# # test = testNaiveBayes(doc, logprior, loglikelihood, C, V)\n",
    "# print(test)\n",
    "\n",
    "# TODO: table of results: accuracy, precision, recall\n",
    "#   column for original, nltk stoplist version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
