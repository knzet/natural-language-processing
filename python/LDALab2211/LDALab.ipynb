{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GeZdakv_uliB"
   },
   "source": [
    "# **Topic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9a2ddvZChYwP"
   },
   "source": [
    "## **Exercise 1.1: Processing the raw text**\n",
    "\n",
    "You will using the gensim python library to perform LDA on the Brown corpus\n",
    "\n",
    "We will start with the file `brown.txt`, which contains 500 documents from the Brown corpus, one document per line, with all punctuation removed.\n",
    "\n",
    "Read these documents into memory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G_WK0jVuhBhV",
    "outputId": "9174a7b2-7992-4eeb-980d-9b0f70b1e1f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [ line.strip() for line in open('brown.txt', 'r') ]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qd-od-p4m2Sg"
   },
   "source": [
    "Split each document into its word tokens and lowercase them, to get a list of lists of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSq3tyGXg-Ho"
   },
   "outputs": [],
   "source": [
    "texts = [ [ w for w in d.lower().split() ] for d in docs ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R54SkbmhhX8Q"
   },
   "source": [
    "We could do some more preprocessing, like stoplisting or removing numbers, etc., but you will see that this doesn’t apply for this lab’s general purpose task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UlA4sGtanhpz"
   },
   "source": [
    "## **Exercise 1.2a: Raw text to bag-of-words**\n",
    "\n",
    "Many sophisticated models like LDA may rely on the bag-of-words representation (i.e. representing a document as unigram frequencies).\n",
    "\n",
    "This is done by creating a unique index of all words in the corpus, then transforming each document into a list of those indexes along with a count of how many times they appear.\n",
    "\n",
    "`gensim` provides a `Dictionary` class for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rnxwYd5WhHEt",
    "outputId": "46e91b21-82a2-40fc-b82f-e6873631072a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48017"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "dictionary = Dictionary(texts)   #Index all words in the corpus\n",
    "len(dictionary)                  #Number of word types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "id": "90mTZ3vQhMcs",
    "outputId": "3214522b-a2b2-4cc4-a3dc-94f102a52143"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rights'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[1729]                 #ID lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w8eoQpQ2hTYf",
    "outputId": "6ca44eb8-1dbd-44b4-df2d-2830f287bde4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1729"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id['rights']    #Word type lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22909"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id['flake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bar', 'barber', 'battle', 'be', 'became', 'become', 'been', 'before', 'begin', 'being', 'believes', 'bellwood', 'berry', 'best', 'birth', 'bit', 'blue', 'board', 'bodys', 'bond', 'bonds', 'both', 'bowden', 'brief', 'brought', 'burden', 'bush', 'but', 'by', 'byrd', 'byrds', 'caldwell', 'caldwells', 'callan', 'calls', 'calmest', 'campaign', 'can', 'candidate', 'candidates', 'career', 'carey', 'carry', 'cent', 'chairman', 'chambers', 'charge', 'charged', 'cheshire', 'child']\n"
     ]
    }
   ],
   "source": [
    "allwords = [ dictionary[i] for i in dictionary ]\n",
    "print(allwords[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 1.2b: Filtering raw text to bag-of-words**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8CxRGiXEnyPx"
   },
   "source": [
    "A common pre-processing task is to remove highly frequent words (e.g. *a, the, of*), as they appear in nearly every document, and thus are uninformative for topics.\n",
    "\n",
    "For topic modeling, it can also be useful to eliminate words that appear in too few documents, as they are not likely associated with any particular topic.\n",
    "\n",
    "Both of these tasks can be accomplished using the `.filter_extremes()` function.\n",
    "\n",
    "Let’s **remove** a word if it appears in fewer than 5 documents (`no_below=5`) or in more than 50%\n",
    "of the documents (`no_above=0.5`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LIwd5TB5hWB8",
    "outputId": "cb7a4a4c-426c-4fa8-d8cb-32123f68ba15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11137"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.filter_extremes(no_below = 5, no_above = 0.5)\n",
    "len(dictionary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cent', 'chairman', 'chambers', 'charge', 'charged', 'child', 'church', 'citizens', 'city', 'clerical', 'combined', 'commented', 'commerce', 'commissioners', 'committee', 'compensation', 'conducted', 'congress', 'congressional', 'congressmen', 'considering', 'consistently', 'constitution', 'constitutional', 'construction', 'consulted', 'continue', 'contracts', 'controversy', 'cost', 'costs', 'council', 'counties', 'county', 'couple', 'courses', 'court', 'courts', 'criticisms', 'crowd', 'cruelty', 'd', 'date', 'daughter', 'davis', 'days', 'death', 'defeated', 'delegation', 'democratic']\n"
     ]
    }
   ],
   "source": [
    "filteredwords = [ dictionary[i] for i in dictionary ]\n",
    "print(filteredwords[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Compare to the above. Which proportion of the vocabular was removed? What do you think was removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S1qlJC6lhe10",
    "outputId": "fae24c6c-ec75-4d86-e5d8-85dbf610a625"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1327"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id['rights']        #Indexes can change after filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary.token2id['flake']          #Some words have disappeared after filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary.token2id['the']            #Some words have disappeared after filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Check to see if you are right about the some of words that were removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'downpayments',\n",
       " 'quadrupling',\n",
       " 'handscreened',\n",
       " 'grudges',\n",
       " 'carson',\n",
       " '480',\n",
       " 'soma',\n",
       " 'accountable',\n",
       " 'simulate',\n",
       " 'melcher',\n",
       " 'cohn',\n",
       " 'tiresome',\n",
       " 'problematic',\n",
       " 'remoteness',\n",
       " 'shams',\n",
       " 'symphonies',\n",
       " 'nautilus',\n",
       " 'rampant',\n",
       " 'untellable',\n",
       " 'eightysixth',\n",
       " 'optics',\n",
       " 'campsites',\n",
       " 'narrated',\n",
       " 'maggoty',\n",
       " 'smiths',\n",
       " 'tensile',\n",
       " 'swimsuit',\n",
       " 'pyknotic',\n",
       " 'apostle',\n",
       " 'hohlbein',\n",
       " 'hopelessness',\n",
       " 'defenseless',\n",
       " 'tsh',\n",
       " 'thayers',\n",
       " 'gradations',\n",
       " 'sect',\n",
       " 'restates',\n",
       " 'despina',\n",
       " 'beowulfs',\n",
       " 'oneiron',\n",
       " 'cruisers',\n",
       " 'notyetmarried',\n",
       " 'rozella',\n",
       " 'audibly',\n",
       " 'perils',\n",
       " 'gantry',\n",
       " '2274',\n",
       " 'oshkosh',\n",
       " 'cott',\n",
       " 'mandamus',\n",
       " 'thankfulness',\n",
       " 'switzer',\n",
       " 'jens',\n",
       " 'grenier',\n",
       " 'communal',\n",
       " 'filming',\n",
       " 'inlet',\n",
       " 'enforceable',\n",
       " 'graybacks',\n",
       " 'exegete',\n",
       " 'ruminants',\n",
       " 'moors',\n",
       " 'perforated',\n",
       " 'pimpled',\n",
       " 'draco',\n",
       " '26yearold',\n",
       " 'igbo',\n",
       " 'diverting',\n",
       " 'shirley',\n",
       " 'entitle',\n",
       " 'icefeeling',\n",
       " 'lattice',\n",
       " 'drummers',\n",
       " 'crystallized',\n",
       " 'habib',\n",
       " 'raided',\n",
       " 'millidegree',\n",
       " 'avid',\n",
       " 'movietobe',\n",
       " 'legitimately',\n",
       " 'sleepwakefulness',\n",
       " 'perfectionism',\n",
       " 'familism',\n",
       " 'innuendo',\n",
       " 'byroads',\n",
       " 'lame',\n",
       " 'splintered',\n",
       " 'earthtouching',\n",
       " 'pulp',\n",
       " 'pavlovsky',\n",
       " 'oozed',\n",
       " 'cranberries',\n",
       " 'warfront',\n",
       " 'mangled',\n",
       " 'bled',\n",
       " 'sho',\n",
       " 'despoilers',\n",
       " 'linearly',\n",
       " 'ob',\n",
       " '770',\n",
       " 'astarte',\n",
       " 'oczakov',\n",
       " 'concorde',\n",
       " 'photocathodes',\n",
       " 'tolerating',\n",
       " 'hable',\n",
       " 'polystyrene',\n",
       " 'fatuous',\n",
       " 'emulated',\n",
       " 'parading',\n",
       " 'tenday',\n",
       " 'artisan',\n",
       " 'landscaping',\n",
       " 'combustion',\n",
       " 'concertmaster',\n",
       " 'alain',\n",
       " 'sixtytwo',\n",
       " 'fiftyfour',\n",
       " 'reavey',\n",
       " 'autoeurope',\n",
       " 'incurable',\n",
       " 'lancashire',\n",
       " 'plinys',\n",
       " 'arthistorian',\n",
       " 'smilingly',\n",
       " 'rosella',\n",
       " 'marston',\n",
       " 'neoclassicists',\n",
       " 'naturallaw',\n",
       " 'terrours',\n",
       " 'crucified',\n",
       " 'marveled',\n",
       " 'rustlin',\n",
       " 'ashley',\n",
       " 'brides',\n",
       " '543',\n",
       " 'methuselah',\n",
       " 'wordgames',\n",
       " 'squalls',\n",
       " '1638',\n",
       " 'unsigned',\n",
       " 'conciliator',\n",
       " 'faires',\n",
       " 'watersheds',\n",
       " 'machado',\n",
       " 'halfstandard',\n",
       " 'cultureprotestantism',\n",
       " 'commends',\n",
       " 'pengally',\n",
       " 'supine',\n",
       " 'specialinterest',\n",
       " 'regattas',\n",
       " 'thiocyanateperchloratefluoro',\n",
       " 'recount',\n",
       " 'aggressiveness',\n",
       " 'mopped',\n",
       " 'coups',\n",
       " 'ellwood',\n",
       " '19511956',\n",
       " 'philibert',\n",
       " '675',\n",
       " 'tumbling',\n",
       " 'inspire',\n",
       " 'marketwise',\n",
       " 'foulest',\n",
       " 'eccentrics',\n",
       " 'digs',\n",
       " 'brothel',\n",
       " 'crucifying',\n",
       " 'taxicab',\n",
       " 'godlike',\n",
       " '11year',\n",
       " 'throneberrys',\n",
       " 'abed',\n",
       " 'sherry',\n",
       " 'dogtown',\n",
       " 'steers',\n",
       " 'bradburys',\n",
       " 'scudding',\n",
       " 'scoreboard',\n",
       " 'stipulate',\n",
       " 'marring',\n",
       " 'kidisoletta',\n",
       " 'gomez',\n",
       " 'mettwurst',\n",
       " 'splattered',\n",
       " 'frenzied',\n",
       " 'lowtemperature',\n",
       " 'viewless',\n",
       " 'engraving',\n",
       " 'laguardia',\n",
       " 'convoluted',\n",
       " 'estellas',\n",
       " 'extrapolate',\n",
       " 'papiermache',\n",
       " 'poolside',\n",
       " 'outworn',\n",
       " 'bigtown',\n",
       " 'kembles',\n",
       " 'passos',\n",
       " 'snakerail',\n",
       " 'ligand',\n",
       " 'stabilizingconserving',\n",
       " 'undeserved',\n",
       " 'ungava',\n",
       " 'grafins',\n",
       " 'lacy',\n",
       " 'anticommunists',\n",
       " 'extinction',\n",
       " 'galatians',\n",
       " 'tsar',\n",
       " 'selfperceived',\n",
       " 'whitemarsh',\n",
       " 'brookfield',\n",
       " 'foiled',\n",
       " 'freightcar',\n",
       " 'agnes',\n",
       " 'fielder',\n",
       " 'triangles',\n",
       " 'moraleenhancing',\n",
       " 'refreshment',\n",
       " 'flaky',\n",
       " 'ascetic',\n",
       " 'campaigne',\n",
       " 'bartha',\n",
       " 'porkbarrel',\n",
       " 'flitting',\n",
       " 'yehudi',\n",
       " '14th',\n",
       " 'afferent',\n",
       " 'cleanshaven',\n",
       " 'rusks',\n",
       " 'absorbency',\n",
       " 'weaselworded',\n",
       " 'provost',\n",
       " 'timidly',\n",
       " 'hereabouts',\n",
       " '9910741',\n",
       " 'indium',\n",
       " 'vistas',\n",
       " 'deploying',\n",
       " 'paot',\n",
       " 'sako',\n",
       " 'overlaps',\n",
       " 'waterways',\n",
       " 'dj',\n",
       " 'bolshoi',\n",
       " 'haw',\n",
       " '1565',\n",
       " 'velvet',\n",
       " 'putout',\n",
       " 'threehundredfoot',\n",
       " 'compliment',\n",
       " 'renewing',\n",
       " 'exclaiming',\n",
       " 'lettering',\n",
       " 'nonspecific',\n",
       " 'bewilders',\n",
       " 'ante',\n",
       " 'sancho',\n",
       " 'nothingness',\n",
       " 'stettin',\n",
       " 'golfs',\n",
       " 'rumanian',\n",
       " 'corrode',\n",
       " 'bog',\n",
       " 'hercule',\n",
       " '3646',\n",
       " 'iodideconcentrating',\n",
       " 'venerated',\n",
       " 'contradistinction',\n",
       " 'arson',\n",
       " 'cardiovascular',\n",
       " 'decidedly',\n",
       " 'swedish',\n",
       " 'bilked',\n",
       " 'decatur',\n",
       " 'appointee',\n",
       " 'geraghty',\n",
       " 'dilys',\n",
       " '402',\n",
       " 'few',\n",
       " 'rethinking',\n",
       " 'playin',\n",
       " 'diana',\n",
       " 'toasting',\n",
       " 'nonpolygynous',\n",
       " 'stanbury',\n",
       " 'chassis',\n",
       " 'unplowed',\n",
       " 'boardinghouses',\n",
       " 'hairtrigger',\n",
       " 'hatchet',\n",
       " 'tulipshaped',\n",
       " 'assists',\n",
       " 'descendants',\n",
       " 'rickards',\n",
       " 'minn',\n",
       " 'hattiesburg',\n",
       " 'artfully',\n",
       " 'jyj',\n",
       " 'balling',\n",
       " 'yachting',\n",
       " '357',\n",
       " 'exasperated',\n",
       " 'uxbridge',\n",
       " 'marskmen',\n",
       " 'snag',\n",
       " 'timetemperature',\n",
       " 'lucius',\n",
       " 'tatler',\n",
       " 'spaciousness',\n",
       " 'disorderliness',\n",
       " 'indubitable',\n",
       " 'sexy',\n",
       " 'rocketbombs',\n",
       " 'midrange',\n",
       " 'hanovers',\n",
       " 'daisies',\n",
       " 'rectifier',\n",
       " 'unsinkable',\n",
       " 'speer',\n",
       " 'wonderingly',\n",
       " 'mckenzie',\n",
       " 'antidiscrimination',\n",
       " 'anarchistadventurers',\n",
       " 'selfassertion',\n",
       " 'lapping',\n",
       " 'partitions',\n",
       " 'acknowledgement',\n",
       " 'insides',\n",
       " 'slingshot',\n",
       " 'magnum',\n",
       " 'binoculars',\n",
       " 'benzell',\n",
       " 'massifs',\n",
       " 'iliac',\n",
       " 'wilde',\n",
       " 'incubation',\n",
       " 'intestine',\n",
       " 'outoftown',\n",
       " 'purcell',\n",
       " 'sweeney',\n",
       " 'streeters',\n",
       " 'nebula',\n",
       " 'barcus',\n",
       " 'laysisters',\n",
       " 'impacted',\n",
       " 'convince',\n",
       " 'injunction',\n",
       " 'whiteness',\n",
       " 'default',\n",
       " 'closeups',\n",
       " 'impinging',\n",
       " 'darin',\n",
       " 'mudsweatandtears',\n",
       " 'pawnshop',\n",
       " 'rowdy',\n",
       " 'godfrey',\n",
       " 'heavyduty',\n",
       " 'yanking',\n",
       " 'shortcuts',\n",
       " 'pollock',\n",
       " '1590',\n",
       " 'indefensible',\n",
       " 'greatgrandson',\n",
       " 'chronically',\n",
       " 'chowders',\n",
       " 'stink',\n",
       " 'ingeniously',\n",
       " 'confusin',\n",
       " 'zaroubin',\n",
       " 'halfaloud',\n",
       " 'fairy',\n",
       " 'pastern',\n",
       " 'administer',\n",
       " 'spectroscopy',\n",
       " 'multiplication',\n",
       " 'fieldsequential',\n",
       " 'diapers',\n",
       " '9748000',\n",
       " 'disaffiliate',\n",
       " 'parisology',\n",
       " 'tint',\n",
       " 'stansbery',\n",
       " 'disregarding',\n",
       " 'woodberry',\n",
       " 'beautify',\n",
       " 'smacks',\n",
       " 'urielites',\n",
       " 'dispell',\n",
       " 'delicately',\n",
       " 'adjourning',\n",
       " 'consonantal',\n",
       " 'unpleased',\n",
       " 'sistersinlaw',\n",
       " 'sorted',\n",
       " 'tarpon',\n",
       " 'boneweary',\n",
       " 'hrothgars',\n",
       " 'luthers',\n",
       " 'diane',\n",
       " 'manning',\n",
       " 'steiner',\n",
       " 'divorcee',\n",
       " 'asteroid',\n",
       " 'maquet',\n",
       " 'unamused',\n",
       " 'febrile',\n",
       " 'sponging',\n",
       " 'myofibrils',\n",
       " 'slenczynka',\n",
       " 'bootlegger',\n",
       " 'dobbs',\n",
       " 'sidelong',\n",
       " 'motioned',\n",
       " 'households',\n",
       " 'place',\n",
       " 'bmt',\n",
       " '2825',\n",
       " 'karen',\n",
       " 'xxxx',\n",
       " 'hir',\n",
       " 'diesel',\n",
       " 'seeley',\n",
       " 'chorines',\n",
       " 'dangled',\n",
       " 'gayess',\n",
       " 'allcounty',\n",
       " 'cavern',\n",
       " 'tantamount',\n",
       " 'rothko',\n",
       " 'muggers',\n",
       " 'mined',\n",
       " 'agatha',\n",
       " 'wansley',\n",
       " 'gimpy',\n",
       " 'spalding',\n",
       " 'centrality',\n",
       " 'ponoluu',\n",
       " 'fiveround',\n",
       " 'err',\n",
       " 'enunciation',\n",
       " 'hytt',\n",
       " 'realms',\n",
       " 'greeting',\n",
       " 'hoops',\n",
       " 'sects',\n",
       " 'antikennedy',\n",
       " 'riviera',\n",
       " 'beeffeeding',\n",
       " 'one',\n",
       " 'blithely',\n",
       " 'bodied',\n",
       " 'pilates',\n",
       " 'sabella',\n",
       " 'myeloid',\n",
       " 'bernini',\n",
       " 'bluntness',\n",
       " 'idlers',\n",
       " 'squirted',\n",
       " 'universalinternational',\n",
       " 'fathered',\n",
       " 'skiway',\n",
       " 'nonpropagandistic',\n",
       " 'whiff',\n",
       " 'bookcases',\n",
       " 'omaha',\n",
       " 'cults',\n",
       " 'alterman',\n",
       " 'rosburg',\n",
       " 'subrogation',\n",
       " 'minnie',\n",
       " 'frightfully',\n",
       " 'josef',\n",
       " 'hartes',\n",
       " 'metamorphosis',\n",
       " 'pawtuxet',\n",
       " 'wragge',\n",
       " 'shellpsychology',\n",
       " 'likened',\n",
       " 'kraut',\n",
       " 'secondfloor',\n",
       " 'vigreux',\n",
       " 'anecdotes',\n",
       " 'mats',\n",
       " 'majdantartarski',\n",
       " 'empiricism',\n",
       " 'malay',\n",
       " 'bewilderedly',\n",
       " 'nonspecifically',\n",
       " 'blakey',\n",
       " 'buoyancy',\n",
       " 'revolting',\n",
       " '1728',\n",
       " 'hypocrisies',\n",
       " 'chesterton',\n",
       " 'subpenas',\n",
       " 'foreclosing',\n",
       " 'screeches',\n",
       " 'mollie',\n",
       " 'slouches',\n",
       " 'adriatic',\n",
       " 'indignities',\n",
       " 'joneses',\n",
       " 'wellbred',\n",
       " 'mawkish',\n",
       " 'admiringly',\n",
       " 'kirovs',\n",
       " 'calculators',\n",
       " 'attakapas',\n",
       " 'geometric',\n",
       " 'dextrousfingered',\n",
       " 'approvingly',\n",
       " 'puny',\n",
       " 'contraception',\n",
       " 'fearfilled',\n",
       " 'accompanist',\n",
       " 'uproariously',\n",
       " 'satirizes',\n",
       " 'mitigates',\n",
       " 'sweatband',\n",
       " 'overburdened',\n",
       " 'fastgrossing',\n",
       " 'symonds',\n",
       " 'shibboleths',\n",
       " 'compositional',\n",
       " 'verdant',\n",
       " 'meaningfulness',\n",
       " 'mailboxes',\n",
       " 'bouts',\n",
       " 'sunbonnet',\n",
       " 'solids',\n",
       " 'boxcar',\n",
       " 'foggia',\n",
       " 'lolly',\n",
       " 'morphine',\n",
       " 'mosquito',\n",
       " 'darwin',\n",
       " 'corpulence',\n",
       " 'existentialism',\n",
       " 'bathyrans',\n",
       " 'gracie',\n",
       " 'moons',\n",
       " 'entanglement',\n",
       " 'neitzbohr',\n",
       " 'yelping',\n",
       " 'jnr',\n",
       " '260',\n",
       " 'preachers',\n",
       " 'polands',\n",
       " 'subroutines',\n",
       " 'insinuated',\n",
       " 'flirted',\n",
       " 'restlessness',\n",
       " 'landscapes',\n",
       " 'andrenas',\n",
       " 'muggy',\n",
       " 'invoke',\n",
       " 'sheila',\n",
       " 'conjecture',\n",
       " 'impudent',\n",
       " 'bland',\n",
       " 'visage',\n",
       " '11744',\n",
       " '1787',\n",
       " '944',\n",
       " 'jerrys',\n",
       " '365',\n",
       " 'disheveled',\n",
       " 'wiligis',\n",
       " 'sirinjani',\n",
       " 'sulks',\n",
       " 'tag',\n",
       " 'casehistory',\n",
       " 'travesty',\n",
       " 'reexplore',\n",
       " '362',\n",
       " 'demographic',\n",
       " 'blockbuster',\n",
       " 'variance',\n",
       " 'chandelle',\n",
       " '2730',\n",
       " 'schmidt',\n",
       " 'accomplishes',\n",
       " 'out',\n",
       " 'conducive',\n",
       " 'sneaky',\n",
       " 'nathaniel',\n",
       " 'cock',\n",
       " 'delude',\n",
       " 'spoilables',\n",
       " 'prickly',\n",
       " 'stockmarket',\n",
       " 'ccb',\n",
       " 'ninetofive',\n",
       " 'vigilant',\n",
       " 'sailorly',\n",
       " 'broadcasters',\n",
       " 'deplored',\n",
       " 'colombia',\n",
       " 'obscene',\n",
       " 'also',\n",
       " 'maes',\n",
       " 'rhinewestphalia',\n",
       " 'harmlessly',\n",
       " 'accessibility',\n",
       " 'predestined',\n",
       " 'dudley',\n",
       " 'avocation',\n",
       " 'yonder',\n",
       " 'yalearmy',\n",
       " 'topeka',\n",
       " 'croaks',\n",
       " 'rattzhenfuut',\n",
       " 'curdling',\n",
       " 'irene',\n",
       " 'entreat',\n",
       " 'crudity',\n",
       " 'capitalists',\n",
       " 'stepmothers',\n",
       " 'pegs',\n",
       " 'shocker',\n",
       " 'interpolated',\n",
       " 'eisler',\n",
       " 'platitudinous',\n",
       " 'ponds',\n",
       " 'baseless',\n",
       " 'cholelithiasis',\n",
       " '2425',\n",
       " 'boxwood',\n",
       " 'windshield',\n",
       " 'psychopathic',\n",
       " 'reefs',\n",
       " 'elisha',\n",
       " 'tareytown',\n",
       " 'clinch',\n",
       " 'fermenting',\n",
       " 'functioned',\n",
       " 'santayana',\n",
       " 'everincreasing',\n",
       " 'doublewall',\n",
       " 'crosssectional',\n",
       " 'selfcrimination',\n",
       " 'scatters',\n",
       " 'je',\n",
       " 'birthplace',\n",
       " 'banshees',\n",
       " 'pathologic',\n",
       " 'stalwart',\n",
       " 'bunyan',\n",
       " 'motheaten',\n",
       " 'masquerades',\n",
       " 'slicker',\n",
       " 'crucifix',\n",
       " 'pacers',\n",
       " 'irsac',\n",
       " '5to2',\n",
       " 'menstruation',\n",
       " 'classifying',\n",
       " 'wallboard',\n",
       " 'breakin',\n",
       " 'mckinley',\n",
       " 'backyard',\n",
       " 'quivered',\n",
       " 'romaniuk',\n",
       " 'billows',\n",
       " 'faintest',\n",
       " 'sohn',\n",
       " 'nj',\n",
       " 'postageprepaid',\n",
       " 'hendry',\n",
       " 'communicated',\n",
       " 'blackcrowned',\n",
       " 'loaders',\n",
       " 'lotion',\n",
       " 'hardtoget',\n",
       " 'photomicrograph',\n",
       " 'nugents',\n",
       " 'liturgical',\n",
       " 'electroshock',\n",
       " 'familarity',\n",
       " 'cleantop',\n",
       " 'abo',\n",
       " 'studentloan',\n",
       " 'spitting',\n",
       " 'cognac',\n",
       " 'indelible',\n",
       " 'fjords',\n",
       " 'advisor',\n",
       " 'posthumous',\n",
       " 'umber',\n",
       " 'catlike',\n",
       " 'confesses',\n",
       " 'evangelism',\n",
       " 'ocular',\n",
       " 'piracy',\n",
       " 'onereel',\n",
       " 'adhere',\n",
       " 'piginfested',\n",
       " 'infest',\n",
       " 'vielleicht',\n",
       " 'autofluorescence',\n",
       " 'squint',\n",
       " 'bridesmaids',\n",
       " 'steed',\n",
       " 'francaise',\n",
       " 'volcanic',\n",
       " 'validly',\n",
       " 'reactionaries',\n",
       " 'vasilievitch',\n",
       " 'crouchs',\n",
       " 'futhermore',\n",
       " 'impresario',\n",
       " 'serpents',\n",
       " 'waterfall',\n",
       " 'stairwell',\n",
       " 'yearold',\n",
       " 'repressions',\n",
       " 'flyers',\n",
       " 'dodges',\n",
       " 'followups',\n",
       " 'quelch',\n",
       " 'tertiary',\n",
       " 'desirability',\n",
       " 'onesixth',\n",
       " 'ecuador',\n",
       " 'duct',\n",
       " 'shimmering',\n",
       " 'boeing',\n",
       " 'dashing',\n",
       " '09',\n",
       " 'pigeons',\n",
       " 'palindromes',\n",
       " 'calamity',\n",
       " 'enquired',\n",
       " 'boastfully',\n",
       " 'greyskied',\n",
       " 'apples',\n",
       " '1870s',\n",
       " 'destroyer',\n",
       " 'skolovskys',\n",
       " 'fortnight',\n",
       " 'trusses',\n",
       " 'reposed',\n",
       " 'halves',\n",
       " 'selfassertive',\n",
       " 'superiors',\n",
       " 'bulls',\n",
       " 'hazlitt',\n",
       " 'simmered',\n",
       " 'fplane',\n",
       " 'potting',\n",
       " 'marker',\n",
       " 'flick',\n",
       " 'ranavan',\n",
       " 'thimble',\n",
       " 'licking',\n",
       " '1823',\n",
       " 'boisterous',\n",
       " 'washer',\n",
       " 'akron',\n",
       " 'sorting',\n",
       " 'intracity',\n",
       " 'darius',\n",
       " 'merleauponty',\n",
       " 'rankandfile',\n",
       " 'negociants',\n",
       " 'flamethrowers',\n",
       " 'khakibound',\n",
       " 'prep',\n",
       " 'titters',\n",
       " 'greyhaired',\n",
       " 'aristotelian',\n",
       " 'bookish',\n",
       " 'trumbull',\n",
       " 'skinless',\n",
       " 'batters',\n",
       " 'clanged',\n",
       " 'briton',\n",
       " 'transience',\n",
       " 'introverted',\n",
       " 'roasted',\n",
       " 'wanta',\n",
       " 'without',\n",
       " 'orbiting',\n",
       " 'dogma',\n",
       " '0605',\n",
       " 'ruining',\n",
       " 'societe',\n",
       " 'figurative',\n",
       " 'lignite',\n",
       " 'shelved',\n",
       " 'misbegotten',\n",
       " 'autocratic',\n",
       " 'tories',\n",
       " '2700',\n",
       " 'rattled',\n",
       " 'bayezit',\n",
       " 'poark',\n",
       " 'nibelungenlied',\n",
       " '538',\n",
       " 'limousines',\n",
       " 'authorizing',\n",
       " 'mosk',\n",
       " '340tr',\n",
       " 'vacancies',\n",
       " 'chatham',\n",
       " 'antimissile',\n",
       " 'deport',\n",
       " 'nononsense',\n",
       " 'prizewinning',\n",
       " 'doorknob',\n",
       " 'preoccupations',\n",
       " '49th',\n",
       " 'phosphor',\n",
       " 'gush',\n",
       " 'iraq',\n",
       " 'devilish',\n",
       " 'disgust',\n",
       " 'judgeship',\n",
       " 'garages',\n",
       " 'undulating',\n",
       " 'rodgers',\n",
       " 'waltham',\n",
       " 'nondiscrimination',\n",
       " '431',\n",
       " 'dirion',\n",
       " 'decisiveness',\n",
       " 'zeffirelli',\n",
       " 'ailey',\n",
       " 'readjusted',\n",
       " 'chaw',\n",
       " 'dynamite',\n",
       " 'leaderless',\n",
       " 'groth',\n",
       " 'rednecked',\n",
       " 'go',\n",
       " 'bourcier',\n",
       " '55987',\n",
       " 'scrapped',\n",
       " 'avowed',\n",
       " 'bucked',\n",
       " 'fallouts',\n",
       " '196',\n",
       " 'corault',\n",
       " 'oskar',\n",
       " 'diabolical',\n",
       " 'camaret',\n",
       " 'impartiality',\n",
       " 'multicolor',\n",
       " 'clara',\n",
       " 'mamma',\n",
       " 'whetted',\n",
       " 'recusant',\n",
       " 'federico',\n",
       " 'stanzaform',\n",
       " 'testimonial',\n",
       " 'imaging',\n",
       " 'corral',\n",
       " 'beerrunners',\n",
       " 'cornbread',\n",
       " 'lenobels',\n",
       " 'zipped',\n",
       " 'shipwrecked',\n",
       " 'concretely',\n",
       " 'anniversaries',\n",
       " 'eeaecellulose',\n",
       " 'uneducated',\n",
       " 'rye',\n",
       " 'flicked',\n",
       " '3300',\n",
       " 'accessions',\n",
       " 'jabbed',\n",
       " 'subgross',\n",
       " 'blotting',\n",
       " 'leatherneck',\n",
       " '72hole',\n",
       " 'hideously',\n",
       " '100ton',\n",
       " 'constantine',\n",
       " 'repressed',\n",
       " 'apology',\n",
       " 'monsters',\n",
       " 'hammetts',\n",
       " 'bosuns',\n",
       " 'credulity',\n",
       " 'leash',\n",
       " 'fibrin',\n",
       " 'sayso',\n",
       " 'blaustein',\n",
       " 'albums',\n",
       " '2052',\n",
       " 'codified',\n",
       " 'blazon',\n",
       " 'rep',\n",
       " 'wilders',\n",
       " 'contingencies',\n",
       " 'macdonald',\n",
       " 'lyman',\n",
       " 'tokens',\n",
       " 'combing',\n",
       " 'hospice',\n",
       " 'comforted',\n",
       " 'nonpolice',\n",
       " '710',\n",
       " 'fallow',\n",
       " 'coconut',\n",
       " 'connivance',\n",
       " 'blimp',\n",
       " 'aspis',\n",
       " 'dissenting',\n",
       " 'dualroadup',\n",
       " 'reformulated',\n",
       " 'downandout',\n",
       " 'piepsam',\n",
       " 'amassing',\n",
       " 'roaringest',\n",
       " 'fling',\n",
       " 'posing',\n",
       " 'costumed',\n",
       " 'halcyon',\n",
       " 'jellyby',\n",
       " 'entwined',\n",
       " 'refill',\n",
       " 'minimizes',\n",
       " 'corniest',\n",
       " 'perilously',\n",
       " 'telephonebooth',\n",
       " 'frontpage',\n",
       " 'cools',\n",
       " 'nippur',\n",
       " 'naturalistic',\n",
       " 'omissions',\n",
       " 'cooperman',\n",
       " 'synchronism',\n",
       " 'button',\n",
       " 'whining',\n",
       " 'sulphur',\n",
       " 'revels',\n",
       " 'mailing',\n",
       " 'alternated',\n",
       " 'condicions',\n",
       " 'flocking',\n",
       " 'jesuits',\n",
       " 'qui',\n",
       " 'gag',\n",
       " 'sixpoint',\n",
       " '380foot',\n",
       " 'nagrin',\n",
       " 'negroappeal',\n",
       " 'untraditional',\n",
       " 'ca',\n",
       " 'expend',\n",
       " 'leopoldville',\n",
       " 'eruption',\n",
       " 'vestige',\n",
       " 'augustines',\n",
       " 'pistolwhipped',\n",
       " 'twain',\n",
       " 'halfoff',\n",
       " 'chaplin',\n",
       " 'anodes',\n",
       " 'marcellus',\n",
       " '367',\n",
       " '1900s',\n",
       " 'modality',\n",
       " 'singleseeded',\n",
       " 'marinade',\n",
       " 'mercifully',\n",
       " 'ultravehement',\n",
       " 'swathed',\n",
       " 'chambered',\n",
       " 'schopenhauer',\n",
       " 'labouisse',\n",
       " 'capitals',\n",
       " 'macroscopically',\n",
       " '989',\n",
       " 'billikens',\n",
       " 'burdensome',\n",
       " 'stomachs',\n",
       " 'comings',\n",
       " 'capacitor',\n",
       " 'forgeries',\n",
       " 'ballard',\n",
       " '4585',\n",
       " 'comprehensively',\n",
       " 'sensitized',\n",
       " 'disdainful',\n",
       " 'topheavy',\n",
       " 'villagers',\n",
       " 'reclining',\n",
       " 'indivisibility',\n",
       " 'aderholds',\n",
       " 'banged',\n",
       " 'completelyrestored',\n",
       " 'cluck',\n",
       " 'instinctual',\n",
       " 'spanning',\n",
       " 'pentagons',\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(allwords) - set(filteredwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How would you only remove words that occur frequenly across the corpus? Why would you (not) want to do this? (Tip: Review cell 52.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T3iYuzW4n9Dp"
   },
   "source": [
    "You can save a dictionary with `.save(filename)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "vIlVJdHPhkDJ",
    "outputId": "67784c76-c4f8-4165-b08c-83a037f3b933"
   },
   "outputs": [],
   "source": [
    "dictionary.save('LDALab.bow.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZsHS_BJoIoL"
   },
   "source": [
    "## **Exercise 1.2c: Processing and serializing the corpus**\n",
    "\n",
    "The function `.doc2bow()` will convert a document to a list of tuples of the unique word indexes in the document and how many times they appear. i.e. [ (word_index, count), (word_index, count), ...]\n",
    "\n",
    "Do this for the entire collection of texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rNPBEqOphvtj",
    "outputId": "66a0bb79-580c-460f-ec04-5f6aa8a902ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 3), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 3), (24, 1), (25, 3), (26, 2), (27, 1), (28, 2), (29, 1), (30, 1), (31, 2), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 3), (48, 2), (49, 1), (50, 1), (51, 1), (52, 2), (53, 1), (54, 1), (55, 1), (56, 2), (57, 2), (58, 1), (59, 1), (60, 1), (61, 1), (62, 5), (63, 1), (64, 2), (65, 1), (66, 2), (67, 1), (68, 1), (69, 2), (70, 1), (71, 1), (72, 2), (73, 1), (74, 1), (75, 3), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 2), (85, 2), (86, 2), (87, 3), (88, 6), (89, 1), (90, 1), (91, 1), (92, 3), (93, 1), (94, 3), (95, 5), (96, 4), (97, 2), (98, 1), (99, 1), (100, 1), (101, 3), (102, 1), (103, 2), (104, 2), (105, 1), (106, 1), (107, 2), (108, 9), (109, 1), (110, 1), (111, 2), (112, 1), (113, 1), (114, 3), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 2), (125, 1), (126, 1), (127, 1), (128, 2), (129, 1), (130, 1), (131, 1), (132, 2), (133, 15), (134, 2), (135, 1), (136, 4), (137, 2), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 3), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 9), (151, 3), (152, 2), (153, 1), (154, 1), (155, 1), (156, 1), (157, 2), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 3), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 3), (178, 14), (179, 1), (180, 2), (181, 1), (182, 2), (183, 1), (184, 1), (185, 1), (186, 2), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 2), (194, 1), (195, 1), (196, 2), (197, 2), (198, 4), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1), (206, 1), (207, 1), (208, 1), (209, 4), (210, 1), (211, 1), (212, 2), (213, 1), (214, 1), (215, 1), (216, 1), (217, 1), (218, 2), (219, 1), (220, 1), (221, 1), (222, 1), (223, 2), (224, 4), (225, 1), (226, 1), (227, 2), (228, 8), (229, 1), (230, 2), (231, 1), (232, 2), (233, 1), (234, 1), (235, 4), (236, 1), (237, 1), (238, 1), (239, 1), (240, 1), (241, 2), (242, 3), (243, 1), (244, 2), (245, 1), (246, 4), (247, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 2), (257, 1), (258, 7), (259, 1), (260, 2), (261, 1), (262, 2), (263, 1), (264, 1), (265, 1), (266, 5), (267, 2), (268, 1), (269, 1), (270, 1), (271, 3), (272, 1), (273, 1), (274, 1), (275, 1), (276, 2), (277, 1), (278, 1), (279, 1), (280, 1), (281, 3), (282, 1), (283, 5), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 3), (291, 1), (292, 2), (293, 1), (294, 3), (295, 1), (296, 18), (297, 1), (298, 1), (299, 1), (300, 1), (301, 3), (302, 2), (303, 1), (304, 1), (305, 1), (306, 4), (307, 4), (308, 1), (309, 1), (310, 1), (311, 1), (312, 3), (313, 1), (314, 1), (315, 1), (316, 1), (317, 1), (318, 1), (319, 1), (320, 2), (321, 1), (322, 1), (323, 1), (324, 1), (325, 1), (326, 4), (327, 3), (328, 1), (329, 1), (330, 2), (331, 1), (332, 1), (333, 1), (334, 1), (335, 1), (336, 2), (337, 5), (338, 5), (339, 2), (340, 1), (341, 1), (342, 1), (343, 1), (344, 1), (345, 1), (346, 4), (347, 2), (348, 1), (349, 1), (350, 3), (351, 1), (352, 1), (353, 2), (354, 1), (355, 2), (356, 1), (357, 1), (358, 1), (359, 1), (360, 1), (361, 1), (362, 2), (363, 1), (364, 1), (365, 1), (366, 1), (367, 2), (368, 3), (369, 1), (370, 1), (371, 1), (372, 1), (373, 1), (374, 1), (375, 2), (376, 1), (377, 2), (378, 1), (379, 2), (380, 1), (381, 1), (382, 2), (383, 1), (384, 2), (385, 2), (386, 4), (387, 1), (388, 1), (389, 1), (390, 2), (391, 1), (392, 1), (393, 1), (394, 1), (395, 2), (396, 1), (397, 2), (398, 3), (399, 1), (400, 2), (401, 1), (402, 1), (403, 3), (404, 1), (405, 1), (406, 1), (407, 1), (408, 1), (409, 1), (410, 4), (411, 1), (412, 2), (413, 1), (414, 2), (415, 1), (416, 1), (417, 1), (418, 2), (419, 1), (420, 1), (421, 1), (422, 1), (423, 2), (424, 1), (425, 1), (426, 2), (427, 1), (428, 2), (429, 2), (430, 1), (431, 1), (432, 4), (433, 2), (434, 1), (435, 1), (436, 1), (437, 1), (438, 1), (439, 1), (440, 1), (441, 4), (442, 1), (443, 1), (444, 1), (445, 4), (446, 1), (447, 1), (448, 1), (449, 1), (450, 1), (451, 1), (452, 1), (453, 1), (454, 1), (455, 1), (456, 1), (457, 2), (458, 5), (459, 1), (460, 1), (461, 1), (462, 2), (463, 9), (464, 1), (465, 1), (466, 1), (467, 2), (468, 2), (469, 1), (470, 4), (471, 1), (472, 1), (473, 1), (474, 6), (475, 1), (476, 1), (477, 1), (478, 2), (479, 2), (480, 1), (481, 5), (482, 1), (483, 1), (484, 1), (485, 2), (486, 2), (487, 1), (488, 1), (489, 1), (490, 2), (491, 1), (492, 1), (493, 1), (494, 2), (495, 1), (496, 1), (497, 1), (498, 1), (499, 1), (500, 1), (501, 1), (502, 1), (503, 1), (504, 1), (505, 1), (506, 2), (507, 1), (508, 1), (509, 1), (510, 12), (511, 1), (512, 1), (513, 1), (514, 1), (515, 1), (516, 1), (517, 2), (518, 2), (519, 2), (520, 3), (521, 2), (522, 1), (523, 1), (524, 2), (525, 1), (526, 1), (527, 2), (528, 1), (529, 2), (530, 1), (531, 1), (532, 3), (533, 2), (534, 1), (535, 1), (536, 1), (537, 1), (538, 1), (539, 1), (540, 1), (541, 2), (542, 1), (543, 1), (544, 1), (545, 1), (546, 1), (547, 1), (548, 1), (549, 2), (550, 2), (551, 1), (552, 1), (553, 1), (554, 1), (555, 1), (556, 2), (557, 1), (558, 1), (559, 2), (560, 1), (561, 1), (562, 4), (563, 2), (564, 4), (565, 1), (566, 2), (567, 1), (568, 1), (569, 1), (570, 1), (571, 1), (572, 1), (573, 1), (574, 1), (575, 1), (576, 4), (577, 1), (578, 3), (579, 1), (580, 2), (581, 1), (582, 2), (583, 5), (584, 1), (585, 1), (586, 1), (587, 1), (588, 3), (589, 2), (590, 1)]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [ dictionary.doc2bow(t) for t in texts ]\n",
    "print (bow_corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8Lq-9HpopL5"
   },
   "source": [
    "This can also be done on unseen documents (unseen words will be ignored):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jHRj2Cg8hxOI",
    "outputId": "47fe2f5e-29af-4352-de27-06a30bec3de3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4022, 1), (7509, 1), (10999, 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2bow('This document has unseen words like Trafalmadorian'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "INgBx7wSh27M",
    "outputId": "9722d3b7-2448-4ced-d7f1-870e1d90157e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('words', 'document', 'unseen')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[4022], dictionary[7509], dictionary[10999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Which words are not indexed? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Hx4avXEo27J"
   },
   "source": [
    "Serializing such a processed corpus allows us to store it and read it back in another time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "7GyTpv87iaPc",
    "outputId": "dbe6ef05-0eaa-4fe3-83cc-11a734a173c4"
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import MmCorpus \n",
    "MmCorpus.serialize('LDALab.bow.mm', bow_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kEMbplbZikmd"
   },
   "source": [
    "## **Exercise 1.3: Bag-of-words to LDA**\n",
    "\n",
    "Let’s train a **30 topic LDA model** on the first 80% of the documents and evaluate it on the remaining 20%.\n",
    "\n",
    "Split the bag-of-words corpus into 80% for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhJTqtyyig6V"
   },
   "outputs": [],
   "source": [
    "size = int(len(bow_corpus) * 4 / 5)\n",
    "training = bow_corpus[:size]\n",
    "testing = bow_corpus[size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZTXKFtIpl10"
   },
   "source": [
    "Now we can train an `LdaModel` object with the following parameters:\n",
    "  * the processed corpus of interest \n",
    "  * `id2word` = the dictionary so that we can print the words instead of the indexes\n",
    "  * `num_topics` = the number of topics (an important parameter to experiment with)\n",
    "  * `passes` = the number of iterations for parameter-learning (we only have 500 documents; larger corpora may involve different number of passes for reasonable results)\n",
    "  \n",
    "**This might take up to 2 minutes or so to run. Please be patient. You can look ahead at instructions below while waiting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPgMmItLiluv"
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "lda30 = LdaModel(training, id2word=dictionary, num_topics=30, passes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lTmpWFCaqJd6"
   },
   "source": [
    "Q5. How do you know if you have chosen a good number of topics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgRJs0gpqQXa"
   },
   "source": [
    "## **Exercise 1.4a: Evaluating LDA - interpreting**\n",
    "\n",
    "The `LdaModel` object has a built-in function to print topics/return raw data `.show_topics()`. Its output is hard to read, so a nicer function `pretty_topics()` has been provided for you.\n",
    "\n",
    "Import the `pretty_topics()` function from `demo` (in the lab directory). It will print the top 10 words and their probabilities per topic. Use this to examine the topics. (Remember: The word distribution is over the full vocabulary, not just frequent words. For a given topic, it sums to 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "Vw9_VomdiuiT",
    "outputId": "622883b4-969f-4cde-90a3-57a53dd02dbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "\t0.01414 states                \n",
      "\t0.01292 wage                  \n",
      "\t0.01051 state                 \n",
      "\t0.01030 industry              \n",
      "\t0.01025 price                 \n",
      "\t0.00932 increase              \n",
      "\t0.00809 rate                  \n",
      "\t0.00685 above                 \n",
      "\t0.00655 basic                 \n",
      "\t0.00646 increases             \n",
      "Topic 2:\n",
      "\t0.00628 she                   \n",
      "\t0.00376 house                 \n",
      "\t0.00293 mrs                   \n",
      "\t0.00289 family                \n",
      "\t0.00278 school                \n",
      "\t0.00272 trial                 \n",
      "\t0.00244 american              \n",
      "\t0.00226 mr                    \n",
      "\t0.00225 music                 \n",
      "\t0.00217 home                  \n",
      "Topic 3:\n",
      "\t0.02389 af                    \n",
      "\t0.00885 1                     \n",
      "\t0.00649 2                     \n",
      "\t0.00553 used                  \n",
      "\t0.00513 temperature           \n",
      "\t0.00506 data                  \n",
      "\t0.00440 system                \n",
      "\t0.00385 radiation             \n",
      "\t0.00365 fiscal                \n",
      "\t0.00350 3                     \n",
      "Topic 4:\n",
      "\t0.01837 she                   \n",
      "\t0.00513 cattle                \n",
      "\t0.00445 house                 \n",
      "\t0.00377 room                  \n",
      "\t0.00369 went                  \n",
      "\t0.00368 men                   \n",
      "\t0.00359 my                    \n",
      "\t0.00344 alfred                \n",
      "\t0.00318 always                \n",
      "\t0.00315 me                    \n",
      "Topic 5:\n",
      "\t0.02497 clay                  \n",
      "\t0.01984 form                  \n",
      "\t0.01830 dictionary            \n",
      "\t0.01784 af                    \n",
      "\t0.01759 information           \n",
      "\t0.01471 text                  \n",
      "\t0.01325 mold                  \n",
      "\t0.01182 cell                  \n",
      "\t0.01175 forms                 \n",
      "\t0.00813 list                  \n",
      "Topic 6:\n",
      "\t0.01411 my                    \n",
      "\t0.01118 me                    \n",
      "\t0.00541 god                   \n",
      "\t0.00424 men                   \n",
      "\t0.00370 am                    \n",
      "\t0.00360 your                  \n",
      "\t0.00358 say                   \n",
      "\t0.00346 she                   \n",
      "\t0.00322 thought               \n",
      "\t0.00319 war                   \n",
      "Topic 7:\n",
      "\t0.00533 program               \n",
      "\t0.00511 state                 \n",
      "\t0.00442 development           \n",
      "\t0.00428 national              \n",
      "\t0.00423 system                \n",
      "\t0.00382 local                 \n",
      "\t0.00332 school                \n",
      "\t0.00332 training              \n",
      "\t0.00326 planning              \n",
      "\t0.00315 programs              \n",
      "Topic 8:\n",
      "\t0.00933 united                \n",
      "\t0.00910 shall                 \n",
      "\t0.00877 states                \n",
      "\t0.00609 board                 \n",
      "\t0.00515 claim                 \n",
      "\t0.00496 hearing               \n",
      "\t0.00482 report                \n",
      "\t0.00456 title                 \n",
      "\t0.00455 folklore              \n",
      "\t0.00455 department            \n",
      "Topic 9:\n",
      "\t0.00880 president             \n",
      "\t0.00789 corps                 \n",
      "\t0.00750 peace                 \n",
      "\t0.00729 faculty               \n",
      "\t0.00714 state                 \n",
      "\t0.00492 year                  \n",
      "\t0.00418 economic              \n",
      "\t0.00401 republican            \n",
      "\t0.00399 plan                  \n",
      "\t0.00372 program               \n",
      "Topic 10:\n",
      "\t0.00711 bridge                \n",
      "\t0.00658 college               \n",
      "\t0.00477 mr                    \n",
      "\t0.00451 board                 \n",
      "\t0.00406 york                  \n",
      "\t0.00406 texas                 \n",
      "\t0.00362 men                   \n",
      "\t0.00334 bill                  \n",
      "\t0.00332 school                \n",
      "\t0.00316 identity              \n",
      "Topic 11:\n",
      "\t0.00490 south                 \n",
      "\t0.00444 my                    \n",
      "\t0.00435 your                  \n",
      "\t0.00393 southern              \n",
      "\t0.00369 negro                 \n",
      "\t0.00349 water                 \n",
      "\t0.00300 me                    \n",
      "\t0.00282 city                  \n",
      "\t0.00266 holmes                \n",
      "\t0.00261 left                  \n",
      "Topic 12:\n",
      "\t0.00957 social                \n",
      "\t0.00733 church                \n",
      "\t0.00596 members               \n",
      "\t0.00401 group                 \n",
      "\t0.00401 students              \n",
      "\t0.00392 catholic              \n",
      "\t0.00391 churches              \n",
      "\t0.00319 means                 \n",
      "\t0.00315 religious             \n",
      "\t0.00307 economic              \n",
      "Topic 13:\n",
      "\t0.00812 your                  \n",
      "\t0.00718 wine                  \n",
      "\t0.00662 tax                   \n",
      "\t0.00576 year                  \n",
      "\t0.00576 she                   \n",
      "\t0.00513 return                \n",
      "\t0.00488 income                \n",
      "\t0.00424 due                   \n",
      "\t0.00406 best                  \n",
      "\t0.00363 red                   \n",
      "Topic 14:\n",
      "\t0.00889 school                \n",
      "\t0.00601 stations              \n",
      "\t0.00562 1                     \n",
      "\t0.00512 artery                \n",
      "\t0.00498 children              \n",
      "\t0.00495 2                     \n",
      "\t0.00487 service               \n",
      "\t0.00459 manchester            \n",
      "\t0.00438 desegregation         \n",
      "\t0.00421 3                     \n",
      "Topic 15:\n",
      "\t0.01716 state                 \n",
      "\t0.01170 seeds                 \n",
      "\t0.01100 vehicles              \n",
      "\t0.00968 states                \n",
      "\t0.00894 god                   \n",
      "\t0.00882 1                     \n",
      "\t0.00852 born                  \n",
      "\t0.00844 cars                  \n",
      "\t0.00731 st                    \n",
      "\t0.00721 seed                  \n",
      "Topic 16:\n",
      "\t0.04775 she                   \n",
      "\t0.00753 jones                 \n",
      "\t0.00668 means                 \n",
      "\t0.00550 medical               \n",
      "\t0.00519 away                  \n",
      "\t0.00517 dogs                  \n",
      "\t0.00494 head                  \n",
      "\t0.00484 feet                  \n",
      "\t0.00443 doctor                \n",
      "\t0.00437 machine               \n",
      "Topic 17:\n",
      "\t0.01019 she                   \n",
      "\t0.00439 himself               \n",
      "\t0.00386 experience            \n",
      "\t0.00379 me                    \n",
      "\t0.00352 my                    \n",
      "\t0.00346 say                   \n",
      "\t0.00318 death                 \n",
      "\t0.00294 often                 \n",
      "\t0.00277 your                  \n",
      "\t0.00275 love                  \n",
      "Topic 18:\n",
      "\t0.01471 af                    \n",
      "\t0.00483 state                 \n",
      "\t0.00442 policy                \n",
      "\t0.00431 law                   \n",
      "\t0.00354 community             \n",
      "\t0.00345 point                 \n",
      "\t0.00344 social                \n",
      "\t0.00326 thus                  \n",
      "\t0.00324 states                \n",
      "\t0.00317 sense                 \n",
      "Topic 19:\n",
      "\t0.02115 brown                 \n",
      "\t0.01237 film                  \n",
      "\t0.01120 sex                   \n",
      "\t0.00939 providence            \n",
      "\t0.00905 john                  \n",
      "\t0.00766 daily                 \n",
      "\t0.00639 browns                \n",
      "\t0.00610 beat                  \n",
      "\t0.00606 sexual                \n",
      "\t0.00595 trial                 \n",
      "Topic 20:\n",
      "\t0.01480 teeth                 \n",
      "\t0.01143 wright                \n",
      "\t0.01101 hands                 \n",
      "\t0.00515 upon                  \n",
      "\t0.00514 she                   \n",
      "\t0.00472 hand                  \n",
      "\t0.00441 administration        \n",
      "\t0.00400 tooth                 \n",
      "\t0.00393 tax                   \n",
      "\t0.00371 mrs                   \n"
     ]
    }
   ],
   "source": [
    "from demo import pretty_topics\n",
    "pretty_topics(lda30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yoOcm1hWquIM"
   },
   "source": [
    "To see more topics than 2, update the variable num_topics in `pretty_topics()` in demo.py by going to the file,  clicking it to open a text editor, revising the variable value, and then saving the file. Then, restart this notebook with `Kernel` > `Restart & Run All`. Be patient and wait a bit.\n",
    "\n",
    "Topics will not be exactly the same because of randomness in the model. \n",
    "\n",
    "Q6. How difficult/straightforward is it to interpret the topics? Do some make more sense than others? \n",
    "\n",
    "Q7. How would you name the topics that do make sense? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIoUGHpCrEH3"
   },
   "source": [
    "## **Exercise 1.4b: Evaluating LDA - perplexity**\n",
    "\n",
    "Now we will compute the **perplexity** of the model on the test data.\n",
    "\n",
    "Remember that LDA is a **generative model**. After training the parameters of the model, let’s test\n",
    "the likelihood of this model randomly generating the held-out test set.\n",
    "\n",
    "The `.log_perplexity()` function of the `LdaModel` will give the log perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hS4RHVvUi1dd",
    "outputId": "9cc3e0e0-4632-4eb0-8fd4-4ab95b0500ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.618870438686745"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_perp = lda30.log_perplexity(testing)\n",
    "lg_perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5wSAL_QUjIbJ",
    "outputId": "c431e930-fa6e-405b-c0fe-9f789706f263"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3145.056977639745"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perp = 2 ** -(lg_perp) # Calculate perplexity \n",
    "perp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uhMG_fa6rTg5"
   },
   "source": [
    "Your results may not be exactly the same, but should be reasonably close.\n",
    "\n",
    "For comparison, using a version of this trained model on an external dataset (not given in lab) yielded a perplexity of 42,224 -- much much worse than on our test set from the same corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. For LDA, do you think perplexity is linked to model interpretability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LDALab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
